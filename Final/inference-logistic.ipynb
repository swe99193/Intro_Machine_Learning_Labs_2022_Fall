{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataset\n",
    "# !cp -r /content/drive/MyDrive/Current\\ Workspace/Intro\\ ML/dataset .\n",
    "# copy model\n",
    "# !cp /content/drive/MyDrive/Current\\ Workspace/Intro\\ ML/models.sav ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = os.path.join(\"dataset\", \"train.csv\")\n",
    "PATH_TEST = os.path.join(\"dataset\", \"test.csv\")\n",
    "PATH_SAMPLE = os.path.join(\"dataset\", \"sample_submission.csv\")\n",
    "submission = pd.read_csv(PATH_SAMPLE)\n",
    "train = pd.read_csv(PATH_TRAIN, index_col='id')\n",
    "test = pd.read_csv(PATH_TEST, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b71686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>measurement_3</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18.040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.213</td>\n",
       "      <td>...</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18.057</td>\n",
       "      <td>...</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>17.295</td>\n",
       "      <td>...</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>19.346</td>\n",
       "      <td>...</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26565</th>\n",
       "      <td>E</td>\n",
       "      <td>158.95</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>16.301</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.177</td>\n",
       "      <td>17.942</td>\n",
       "      <td>10.112</td>\n",
       "      <td>15.795</td>\n",
       "      <td>18.572</td>\n",
       "      <td>16.144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26566</th>\n",
       "      <td>E</td>\n",
       "      <td>146.02</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>17.543</td>\n",
       "      <td>...</td>\n",
       "      <td>11.242</td>\n",
       "      <td>14.179</td>\n",
       "      <td>20.564</td>\n",
       "      <td>10.234</td>\n",
       "      <td>14.450</td>\n",
       "      <td>14.322</td>\n",
       "      <td>13.146</td>\n",
       "      <td>16.471</td>\n",
       "      <td>853.924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26567</th>\n",
       "      <td>E</td>\n",
       "      <td>115.62</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15.670</td>\n",
       "      <td>...</td>\n",
       "      <td>11.407</td>\n",
       "      <td>16.437</td>\n",
       "      <td>17.476</td>\n",
       "      <td>8.668</td>\n",
       "      <td>15.069</td>\n",
       "      <td>16.599</td>\n",
       "      <td>15.590</td>\n",
       "      <td>14.065</td>\n",
       "      <td>750.364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26568</th>\n",
       "      <td>E</td>\n",
       "      <td>106.38</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>18.059</td>\n",
       "      <td>...</td>\n",
       "      <td>11.392</td>\n",
       "      <td>17.064</td>\n",
       "      <td>17.814</td>\n",
       "      <td>14.928</td>\n",
       "      <td>16.273</td>\n",
       "      <td>15.485</td>\n",
       "      <td>13.624</td>\n",
       "      <td>12.865</td>\n",
       "      <td>730.156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26569</th>\n",
       "      <td>E</td>\n",
       "      <td>131.20</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>18.034</td>\n",
       "      <td>...</td>\n",
       "      <td>10.611</td>\n",
       "      <td>15.603</td>\n",
       "      <td>19.703</td>\n",
       "      <td>11.006</td>\n",
       "      <td>15.875</td>\n",
       "      <td>13.366</td>\n",
       "      <td>16.527</td>\n",
       "      <td>17.890</td>\n",
       "      <td>602.354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26570 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n",
       "id                                                                              \n",
       "0                A    80.10  material_7  material_8            9            5   \n",
       "1                A    84.89  material_7  material_8            9            5   \n",
       "2                A    82.43  material_7  material_8            9            5   \n",
       "3                A   101.07  material_7  material_8            9            5   \n",
       "4                A   188.06  material_7  material_8            9            5   \n",
       "...            ...      ...         ...         ...          ...          ...   \n",
       "26565            E   158.95  material_7  material_6            6            9   \n",
       "26566            E   146.02  material_7  material_6            6            9   \n",
       "26567            E   115.62  material_7  material_6            6            9   \n",
       "26568            E   106.38  material_7  material_6            6            9   \n",
       "26569            E   131.20  material_7  material_6            6            9   \n",
       "\n",
       "       measurement_0  measurement_1  measurement_2  measurement_3  ...  \\\n",
       "id                                                                 ...   \n",
       "0                  7              8              4         18.040  ...   \n",
       "1                 14              3              3         18.213  ...   \n",
       "2                 12              1              5         18.057  ...   \n",
       "3                 13              2              6         17.295  ...   \n",
       "4                  9              2              8         19.346  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "26565              6             16              4         16.301  ...   \n",
       "26566             10             12              8         17.543  ...   \n",
       "26567              1             10              1         15.670  ...   \n",
       "26568              2              9              4         18.059  ...   \n",
       "26569              6             19              1         18.034  ...   \n",
       "\n",
       "       measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
       "id                                                                     \n",
       "0             10.672          15.859          17.594          15.193   \n",
       "1             12.448          17.947          17.915          11.755   \n",
       "2             12.715          15.607             NaN          13.798   \n",
       "3             12.471          16.346          18.377          10.020   \n",
       "4             10.337          17.082          19.932          12.428   \n",
       "...              ...             ...             ...             ...   \n",
       "26565            NaN          12.177          17.942          10.112   \n",
       "26566         11.242          14.179          20.564          10.234   \n",
       "26567         11.407          16.437          17.476           8.668   \n",
       "26568         11.392          17.064          17.814          14.928   \n",
       "26569         10.611          15.603          19.703          11.006   \n",
       "\n",
       "       measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
       "id                                                                      \n",
       "0              15.029             NaN          13.034          14.684   \n",
       "1              14.732          15.425          14.395          15.631   \n",
       "2              16.711          18.631          14.094          17.946   \n",
       "3              15.250          15.562          16.154          17.172   \n",
       "4              16.182          12.760          13.153          16.412   \n",
       "...               ...             ...             ...             ...   \n",
       "26565          15.795          18.572          16.144             NaN   \n",
       "26566          14.450          14.322          13.146          16.471   \n",
       "26567          15.069          16.599          15.590          14.065   \n",
       "26568          16.273          15.485          13.624          12.865   \n",
       "26569          15.875          13.366          16.527          17.890   \n",
       "\n",
       "       measurement_17  failure  \n",
       "id                              \n",
       "0             764.100        0  \n",
       "1             682.057        0  \n",
       "2             663.376        0  \n",
       "3             826.282        0  \n",
       "4             579.885        0  \n",
       "...               ...      ...  \n",
       "26565         729.131        0  \n",
       "26566         853.924        0  \n",
       "26567         750.364        0  \n",
       "26568         730.156        0  \n",
       "26569         602.354        0  \n",
       "\n",
       "[26570 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODEL = 'models.sav'\n",
    "models = joblib.load(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75a4224",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-08-31T01:30:30.893555Z",
     "iopub.status.busy": "2022-08-31T01:30:30.893148Z",
     "iopub.status.idle": "2022-08-31T01:30:30.915751Z",
     "shell.execute_reply": "2022-08-31T01:30:30.914859Z"
    },
    "papermill": {
     "duration": 0.035115,
     "end_time": "2022-08-31T01:30:30.917906",
     "exception": false,
     "start_time": "2022-08-31T01:30:30.882791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(df_train, df_test):\n",
    "    data = pd.concat([df_train, df_test])\n",
    "\n",
    "    data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n",
    "    data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n",
    "    data['area'] = data['attribute_2'] * data['attribute_3']\n",
    "\n",
    "    # key: top 10 best measurement columns\n",
    "    # value: for each product code, there is a list of training features used to fill the missing cells in Phase 1\n",
    "    fill_dict = dict()\n",
    "    fill_dict['measurement_17'] = {\n",
    "        'A': ['measurement_5', 'measurement_6', 'measurement_8'],\n",
    "        'B': ['measurement_4', 'measurement_5', 'measurement_7'],\n",
    "        'C': ['measurement_5', 'measurement_7', 'measurement_8', 'measurement_9'],\n",
    "        'D': ['measurement_5', 'measurement_6', 'measurement_7', 'measurement_8'],\n",
    "        'E': ['measurement_4', 'measurement_5', 'measurement_6', 'measurement_8'],\n",
    "        'F': ['measurement_4', 'measurement_5', 'measurement_6', 'measurement_7'],\n",
    "        'G': ['measurement_4', 'measurement_6', 'measurement_8', 'measurement_9'],\n",
    "        'H': ['measurement_4', 'measurement_5', 'measurement_7', 'measurement_8', 'measurement_9'],\n",
    "        'I': ['measurement_3', 'measurement_7', 'measurement_8']\n",
    "    }\n",
    "\n",
    "    #  1. select top 10 best measurement columns, selected by highest correlation value (except 17, done above):\n",
    "    exclude_column = ['product_code', 'loading', 'attribute_0', 'attribute_1',\n",
    "                      'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1', 'loading', 'm3_missing', 'm5_missing']   # exclude these columns from correlation\n",
    "    col_a = [f'measurement_{i}' for i in range(3, 17)]\n",
    "    col_b = []\n",
    "    measurement_df = data.drop(exclude_column, axis=1)\n",
    "    corr_df = measurement_df.corr()\n",
    "\n",
    "    # sum the top 3(exclude self) correlation values as the correlation score, for each feature\n",
    "    for i in range(3, 17):\n",
    "        corr = sorted(np.absolute(corr_df[f'measurement_{i}']), reverse=True)\n",
    "        col_b.append(np.sum(corr[1:4]))\n",
    "\n",
    "    corr_rank = pd.DataFrame()\n",
    "    corr_rank['columnName'] = col_a\n",
    "    corr_rank['correlation score'] = col_b\n",
    "    corr_rank = corr_rank.sort_values(\n",
    "        by='correlation score', ascending=False).reset_index(drop=True)\n",
    "    # print(col_a)\n",
    "    # print(col_b)\n",
    "    print(\"corr_rank:\")\n",
    "    print(corr_rank)\n",
    "\n",
    "    # 2. select training features\n",
    "    # select top 4(exclude self) correlation values columns as training features (for each product_code, for each top 10 columns)\n",
    "    for i in range(10):\n",
    "        target_column = corr_rank['columnName'][i]\n",
    "        tmp_fill_dict = {}\n",
    "        for x in data[\"product_code\"].unique():\n",
    "            mini_corr_df = data[data[\"product_code\"] == x].drop(\n",
    "                exclude_column, axis=1).corr()\n",
    "            corr = np.absolute(mini_corr_df[target_column]).sort_values(\n",
    "                ascending=False)\n",
    "            tmp_fill_dict[x] = corr[1:5].index.tolist()\n",
    "\n",
    "        fill_dict[target_column] = tmp_fill_dict\n",
    "\n",
    "    print(\"fill_dict:\")\n",
    "    for x, y in fill_dict.items():\n",
    "        print(x)\n",
    "        print(\"     \", y)\n",
    "        print()\n",
    "\n",
    "    feature_miss = [f'measurement_{i}' for i in range(0, 18)] + ['loading']\n",
    "\n",
    "    # 3. fill missing values (group by product_code)\n",
    "    for code in data[\"product_code\"].unique():\n",
    "        # Phase1: HuberRegressor\n",
    "        # fill the missing values of each target feature (top 10 best measurement columns)\n",
    "        for target_column in list(fill_dict.keys()):\n",
    "            tmp = data[data[\"product_code\"] == code]\n",
    "\n",
    "            # training features to fill missing cells\n",
    "            feat_column = fill_dict[target_column][code]\n",
    "\n",
    "            tmp_train = tmp[feat_column+[target_column]].dropna(how='any')\n",
    "\n",
    "            # select rows that have missing value of target feature, and fill their target feature\n",
    "            # extra condition: if all of its training features exists\n",
    "            tmp_test = tmp[(tmp[feat_column].isnull().sum(axis=1)\n",
    "                            == 0) & (tmp[target_column].isnull())]\n",
    "\n",
    "            model_HR = HuberRegressor(epsilon=1.9)\n",
    "            model_HR.fit(tmp_train[feat_column], tmp_train[target_column])\n",
    "\n",
    "            # fill target feature\n",
    "            data.loc[(data[\"product_code\"] == code) & (data[feat_column].isnull().sum(axis=1) == 0) & (\n",
    "                data[target_column].isnull()), target_column] = model_HR.predict(tmp_test[feat_column])\n",
    "\n",
    "        # Phase2: KNNImputer\n",
    "        # fill the remaining missing cells\n",
    "        model_KNN = KNNImputer(n_neighbors=3)\n",
    "        data.loc[data[\"product_code\"] == code, feature_miss] = model_KNN.fit_transform(\n",
    "            data.loc[data[\"product_code\"] == code, feature_miss])\n",
    "\n",
    "    columns = [f'measurement_{i}' for i in range(3, 17)]\n",
    "    data['measurement_avg'] = data[columns].mean(axis=1)\n",
    "\n",
    "    df_train_new = data.iloc[:df_train.shape[0], :]\n",
    "    df_test_new = data.iloc[df_train.shape[0]:, :]\n",
    "\n",
    "    return df_train_new, df_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr_rank:\n",
      "        columnName  correlation score\n",
      "0    measurement_8           0.454339\n",
      "1   measurement_11           0.395141\n",
      "2    measurement_5           0.386080\n",
      "3    measurement_6           0.364810\n",
      "4    measurement_7           0.335832\n",
      "5    measurement_4           0.330860\n",
      "6   measurement_15           0.300999\n",
      "7   measurement_10           0.300148\n",
      "8   measurement_16           0.251591\n",
      "9   measurement_14           0.224950\n",
      "10   measurement_9           0.200675\n",
      "11  measurement_13           0.166342\n",
      "12  measurement_12           0.142478\n",
      "13   measurement_3           0.091591\n",
      "fill_dict:\n",
      "measurement_17\n",
      "      {'A': ['measurement_5', 'measurement_6', 'measurement_8'], 'B': ['measurement_4', 'measurement_5', 'measurement_7'], 'C': ['measurement_5', 'measurement_7', 'measurement_8', 'measurement_9'], 'D': ['measurement_5', 'measurement_6', 'measurement_7', 'measurement_8'], 'E': ['measurement_4', 'measurement_5', 'measurement_6', 'measurement_8'], 'F': ['measurement_4', 'measurement_5', 'measurement_6', 'measurement_7'], 'G': ['measurement_4', 'measurement_6', 'measurement_8', 'measurement_9'], 'H': ['measurement_4', 'measurement_5', 'measurement_7', 'measurement_8', 'measurement_9'], 'I': ['measurement_3', 'measurement_7', 'measurement_8']}\n",
      "\n",
      "measurement_8\n",
      "      {'A': ['measurement_17', 'measurement_2', 'measurement_11', 'measurement_14'], 'B': ['measurement_16', 'measurement_10', 'measurement_15', 'measurement_12'], 'C': ['measurement_17', 'failure', 'measurement_6', 'measurement_15'], 'D': ['measurement_17', 'measurement_16', 'measurement_5', 'failure'], 'E': ['measurement_17', 'measurement_13', 'measurement_11', 'measurement_15'], 'F': ['measurement_10', 'measurement_13', 'measurement_7', 'measurement_9'], 'G': ['measurement_17', 'measurement_5', 'measurement_6', 'measurement_2'], 'H': ['measurement_17', 'measurement_12', 'measurement_15', 'measurement_4'], 'I': ['measurement_17', 'measurement_13', 'measurement_4', 'measurement_5']}\n",
      "\n",
      "measurement_11\n",
      "      {'A': ['measurement_14', 'measurement_16', 'measurement_12', 'measurement_15'], 'B': ['measurement_13', 'measurement_10', 'measurement_15', 'measurement_16'], 'C': ['measurement_14', 'measurement_12', 'measurement_16', 'measurement_15'], 'D': ['measurement_2', 'measurement_5', 'measurement_9', 'measurement_7'], 'E': ['measurement_16', 'measurement_14', 'measurement_12', 'measurement_17'], 'F': ['measurement_16', 'measurement_10', 'measurement_15', 'measurement_13'], 'G': ['measurement_10', 'measurement_16', 'measurement_14', 'measurement_15'], 'H': ['measurement_16', 'measurement_12', 'measurement_10', 'measurement_15'], 'I': ['measurement_14', 'measurement_16', 'measurement_12', 'measurement_13']}\n",
      "\n",
      "measurement_5\n",
      "      {'A': ['measurement_17', 'measurement_6', 'measurement_14', 'measurement_16'], 'B': ['measurement_17', 'measurement_12', 'measurement_10', 'measurement_15'], 'C': ['measurement_17', 'measurement_3', 'measurement_7', 'measurement_2'], 'D': ['measurement_17', 'measurement_8', 'measurement_12', 'measurement_11'], 'E': ['measurement_17', 'failure', 'measurement_4', 'measurement_13'], 'F': ['measurement_17', 'measurement_15', 'measurement_16', 'measurement_9'], 'G': ['measurement_17', 'measurement_7', 'measurement_15', 'measurement_10'], 'H': ['measurement_17', 'measurement_7', 'measurement_11', 'measurement_12'], 'I': ['measurement_6', 'measurement_17', 'measurement_4', 'measurement_8']}\n",
      "\n",
      "measurement_6\n",
      "      {'A': ['measurement_17', 'measurement_12', 'measurement_15', 'measurement_2'], 'B': ['measurement_10', 'measurement_12', 'measurement_14', 'measurement_15'], 'C': ['measurement_17', 'measurement_13', 'measurement_16', 'measurement_8'], 'D': ['measurement_17', 'measurement_2', 'failure', 'measurement_13'], 'E': ['measurement_17', 'failure', 'measurement_5', 'measurement_10'], 'F': ['measurement_17', 'measurement_9', 'measurement_10', 'measurement_7'], 'G': ['measurement_17', 'measurement_4', 'measurement_2', 'measurement_15'], 'H': ['measurement_17', 'measurement_4', 'measurement_10', 'measurement_16'], 'I': ['measurement_12', 'measurement_5', 'measurement_8', 'measurement_17']}\n",
      "\n",
      "measurement_7\n",
      "      {'A': ['measurement_17', 'measurement_4', 'measurement_11', 'measurement_15'], 'B': ['measurement_17', 'measurement_3', 'failure', 'measurement_11'], 'C': ['measurement_17', 'measurement_16', 'measurement_5', 'measurement_9'], 'D': ['measurement_17', 'failure', 'measurement_15', 'measurement_2'], 'E': ['measurement_16', 'measurement_11', 'measurement_6', 'measurement_4'], 'F': ['measurement_17', 'measurement_14', 'measurement_3', 'measurement_10'], 'G': ['measurement_10', 'measurement_4', 'measurement_5', 'measurement_9'], 'H': ['measurement_17', 'measurement_11', 'measurement_14', 'measurement_5'], 'I': ['measurement_17', 'measurement_14', 'measurement_10', 'measurement_9']}\n",
      "\n",
      "measurement_4\n",
      "      {'A': ['measurement_17', 'measurement_9', 'measurement_12', 'measurement_16'], 'B': ['measurement_17', 'measurement_10', 'measurement_12', 'measurement_14'], 'C': ['measurement_3', 'measurement_14', 'failure', 'measurement_2'], 'D': ['measurement_15', 'measurement_6', 'failure', 'measurement_7'], 'E': ['measurement_17', 'measurement_15', 'measurement_5', 'failure'], 'F': ['measurement_17', 'measurement_16', 'measurement_11', 'measurement_3'], 'G': ['measurement_17', 'measurement_6', 'measurement_7', 'measurement_11'], 'H': ['measurement_17', 'measurement_6', 'measurement_8', 'measurement_16'], 'I': ['measurement_17', 'measurement_8', 'measurement_5', 'measurement_6']}\n",
      "\n",
      "measurement_15\n",
      "      {'A': ['measurement_12', 'measurement_16', 'measurement_14', 'measurement_11'], 'B': ['measurement_16', 'measurement_13', 'measurement_11', 'measurement_10'], 'C': ['measurement_16', 'measurement_14', 'measurement_12', 'measurement_13'], 'D': ['measurement_16', 'measurement_12', 'measurement_10', 'measurement_14'], 'E': ['measurement_12', 'measurement_4', 'measurement_10', 'measurement_16'], 'F': ['measurement_16', 'measurement_11', 'measurement_10', 'measurement_5'], 'G': ['measurement_10', 'measurement_14', 'measurement_11', 'measurement_9'], 'H': ['measurement_12', 'measurement_16', 'measurement_11', 'measurement_14'], 'I': ['measurement_13', 'measurement_11', 'measurement_3', 'measurement_16']}\n",
      "\n",
      "measurement_10\n",
      "      {'A': ['measurement_15', 'measurement_9', 'measurement_16', 'measurement_6'], 'B': ['measurement_11', 'measurement_13', 'measurement_15', 'measurement_16'], 'C': ['measurement_14', 'measurement_2', 'measurement_7', 'measurement_5'], 'D': ['measurement_14', 'measurement_12', 'measurement_15', 'measurement_16'], 'E': ['measurement_14', 'measurement_12', 'measurement_16', 'measurement_13'], 'F': ['measurement_16', 'measurement_11', 'measurement_13', 'measurement_15'], 'G': ['measurement_11', 'measurement_14', 'measurement_15', 'measurement_16'], 'H': ['measurement_16', 'measurement_11', 'measurement_12', 'measurement_15'], 'I': ['measurement_7', 'measurement_3', 'measurement_11', 'measurement_5']}\n",
      "\n",
      "measurement_16\n",
      "      {'A': ['measurement_15', 'measurement_12', 'measurement_14', 'measurement_11'], 'B': ['measurement_13', 'measurement_15', 'measurement_11', 'measurement_10'], 'C': ['measurement_15', 'measurement_14', 'measurement_11', 'measurement_7'], 'D': ['measurement_15', 'measurement_12', 'measurement_10', 'measurement_8'], 'E': ['measurement_11', 'measurement_12', 'measurement_10', 'measurement_14'], 'F': ['measurement_13', 'measurement_11', 'measurement_10', 'measurement_15'], 'G': ['measurement_14', 'measurement_11', 'measurement_10', 'measurement_9'], 'H': ['measurement_11', 'measurement_10', 'measurement_15', 'measurement_7'], 'I': ['measurement_13', 'measurement_11', 'measurement_14', 'measurement_12']}\n",
      "\n",
      "measurement_14\n",
      "      {'A': ['measurement_11', 'measurement_12', 'measurement_16', 'measurement_15'], 'B': ['measurement_10', 'measurement_6', 'failure', 'measurement_4'], 'C': ['measurement_11', 'measurement_16', 'measurement_15', 'failure'], 'D': ['measurement_10', 'measurement_15', 'measurement_12', 'failure'], 'E': ['measurement_11', 'measurement_10', 'measurement_12', 'measurement_16'], 'F': ['measurement_7', 'measurement_11', 'measurement_9', 'measurement_2'], 'G': ['measurement_16', 'measurement_10', 'measurement_11', 'measurement_15'], 'H': ['measurement_7', 'measurement_15', 'measurement_12', 'measurement_5'], 'I': ['measurement_11', 'measurement_16', 'measurement_12', 'measurement_13']}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/hsiao/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "train, test = data_preprocessing(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce1b89",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7115c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['loading', 'attribute_0', 'measurement_17', 'measurement_0',\n",
    "                 'measurement_1', 'measurement_2', 'area', 'm3_missing', 'm5_missing', 'measurement_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bf2e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models, test, features_list):\n",
    "    preds = np.zeros(test.shape[0])\n",
    "\n",
    "    # take average value of all models\n",
    "    for i in range(10):\n",
    "        preds += models[i].predict_proba(test[features_list])[:, 1] / 10\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d472cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['failure'] = predict(models, test, features_list)\n",
    "submission.to_csv('submission_0811521.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp submission_0811521.csv /content/drive/MyDrive/Current\\ Workspace/Intro\\ ML/dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c34019f22b2cb8c0f12492c2d56cc88834c9a1831a9952841115fc570b129000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
